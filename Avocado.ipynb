{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint ,EarlyStopping,ReduceLROnPlateau\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Activation,Input,GlobalAveragePooling2D,Flatten\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetPath = './Avocado/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "ripe_train_path = datasetPath+'train/Ripe/'\n",
    "unripe_train_path = datasetPath+'train/Unripe/'\n",
    "ripe_validation_path = datasetPath+'validation/Ripe/'\n",
    "unripe_validation_path = datasetPath+'validation/Unripe/'\n",
    "ripe_test_path = datasetPath+'test/Ripe/'\n",
    "unripe_test_path = datasetPath+'test/Unripe/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ripe_train = []\n",
    "for root, subdirs, files in os.walk(ripe_train_path):\n",
    "    for elem in files:\n",
    "        img = tf.keras.preprocessing.image.load_img(ripe_train_path+elem, target_size=(224, 224))\n",
    "        new_img = np.array(img, dtype=np.float64)/255.0\n",
    "        ripe_train.append(np.expand_dims(new_img, axis=0))\n",
    "unripe_train = []\n",
    "for root, subdirs, files in os.walk(unripe_train_path):\n",
    "    for elem in files:\n",
    "        img = tf.keras.preprocessing.image.load_img(unripe_train_path+elem, target_size=(224, 224))\n",
    "        new_img = np.array(img, dtype=np.float64)/255.0\n",
    "        unripe_train.append(np.expand_dims(new_img, axis=0))\n",
    "#######################\n",
    "ripe_truth = [0 for i in range(0, len(ripe_train))]\n",
    "unripe_truth = [0 for i in range(0, len(unripe_train))]\n",
    "#######################\n",
    "\n",
    "data_train = []\n",
    "data_train.append(ripe_train)\n",
    "data_train.append(unripe_train)\n",
    "data_train = [val for sublist in data_train for val in sublist]\n",
    "\n",
    "all_y_truth = []\n",
    "all_y_truth.append(ripe_truth)\n",
    "all_y_truth.append(unripe_truth)\n",
    "all_y_truth = [val for sublist in all_y_truth for val in sublist]\n",
    "\n",
    "## split train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(data_train,all_y_truth,test_size=0.2)\n",
    "validation_data = zip(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 748 images belonging to 2 classes.\n",
      "Found 170 images belonging to 2 classes.\n",
      "Found 309 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path_dir = os.path.join(datasetPath, 'train')\n",
    "val_path_dir = os.path.join(datasetPath, 'validation')\n",
    "test_path_dir = os.path.join(datasetPath, 'test')\n",
    "\n",
    "#train_path_dir = \"/content/data/Avocado/Training\"\n",
    "#val_path_dir = \"/content/data/Avocado/Validation\"\n",
    "#491 + 427\n",
    "\n",
    "img_size = (224, 224)\n",
    "batchsize = 16 \n",
    "\n",
    "\n",
    "#### Train #####\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                 rotation_range=40,\n",
    "                                 width_shift_range=0.2,\n",
    "                                 height_shift_range=0.2,\n",
    "                                 shear_range=0.2,\n",
    "                                 zoom_range=0.2,\n",
    "                                 horizontal_flip=True,\n",
    "                                 fill_mode='nearest') \n",
    "train_generator = train_datagen.flow_from_directory(train_path_dir,\n",
    "                                                  target_size=img_size,\n",
    "                                                  color_mode='rgb',\n",
    "                                                  batch_size=batchsize,\n",
    "                                                  class_mode='binary',\n",
    "                                                  shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Validation #####\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "val_generator = val_datagen.flow_from_directory(val_path_dir,\n",
    "                                                target_size=img_size,\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=batchsize,\n",
    "                                                class_mode='binary',\n",
    "                                                shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Test #####\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_generator = val_datagen.flow_from_directory(test_path_dir,\n",
    "                                                target_size=img_size,\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=batchsize,\n",
    "                                                class_mode='binary',\n",
    "                                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG16 Model, where it's Fully Connected Layers (top layer) is removed\n",
    "base_model = keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3),pooling=None)\n",
    "x = base_model.output\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(x)\n",
    "# Add a fully connected layer\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "# Tried adam previously, but I think sigmoid is better for binary\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd,loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "# Checkpoints to stop model if validation loss is not decreasing\n",
    "ModelCheckpointcheckpoint = ModelCheckpoint(\"best_model.h5\",monitor='val_loss',mode='min',save_best_only=True,verbose=1)\n",
    "EarlyStoppingearlystop = EarlyStopping(monitor = 'val_loss',min_delta = 0,patience = 10,verbose = 1,restore_best_weights = True)\n",
    "reducelr=ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "callbacks=[ModelCheckpointcheckpoint,EarlyStoppingearlystop,reducelr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "sys.modules['Image'] = Image \n",
    "from PIL import Image\n",
    "import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6857 - accuracy: 0.5287\n",
      "Epoch 00001: val_loss improved from inf to 0.70808, saving model to best_model.h5\n",
      "46/46 [==============================] - 162s 4s/step - loss: 0.6857 - accuracy: 0.5287 - val_loss: 0.7081 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6527 - accuracy: 0.6325\n",
      "Epoch 00002: val_loss improved from 0.70808 to 0.66511, saving model to best_model.h5\n",
      "46/46 [==============================] - 149s 3s/step - loss: 0.6527 - accuracy: 0.6325 - val_loss: 0.6651 - val_accuracy: 0.5938\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6378 - accuracy: 0.7008\n",
      "Epoch 00003: val_loss improved from 0.66511 to 0.64524, saving model to best_model.h5\n",
      "46/46 [==============================] - 143s 3s/step - loss: 0.6378 - accuracy: 0.7008 - val_loss: 0.6452 - val_accuracy: 0.5750\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.6035 - accuracy: 0.7609\n",
      "Epoch 00004: val_loss improved from 0.64524 to 0.62038, saving model to best_model.h5\n",
      "46/46 [==============================] - 139s 3s/step - loss: 0.6035 - accuracy: 0.7609 - val_loss: 0.6204 - val_accuracy: 0.6062\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5915 - accuracy: 0.7732\n",
      "Epoch 00005: val_loss improved from 0.62038 to 0.59849, saving model to best_model.h5\n",
      "46/46 [==============================] - 138s 3s/step - loss: 0.5915 - accuracy: 0.7732 - val_loss: 0.5985 - val_accuracy: 0.6187\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5816 - accuracy: 0.7705\n",
      "Epoch 00006: val_loss improved from 0.59849 to 0.58198, saving model to best_model.h5\n",
      "46/46 [==============================] - 140s 3s/step - loss: 0.5816 - accuracy: 0.7705 - val_loss: 0.5820 - val_accuracy: 0.6938\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.8361\n",
      "Epoch 00007: val_loss improved from 0.58198 to 0.57186, saving model to best_model.h5\n",
      "46/46 [==============================] - 133s 3s/step - loss: 0.5652 - accuracy: 0.8361 - val_loss: 0.5719 - val_accuracy: 0.6562\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5433 - accuracy: 0.8525\n",
      "Epoch 00008: val_loss improved from 0.57186 to 0.53897, saving model to best_model.h5\n",
      "46/46 [==============================] - 134s 3s/step - loss: 0.5433 - accuracy: 0.8525 - val_loss: 0.5390 - val_accuracy: 0.9250\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5312 - accuracy: 0.8907\n",
      "Epoch 00009: val_loss improved from 0.53897 to 0.52520, saving model to best_model.h5\n",
      "46/46 [==============================] - 136s 3s/step - loss: 0.5312 - accuracy: 0.8907 - val_loss: 0.5252 - val_accuracy: 0.9250\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5249 - accuracy: 0.8893\n",
      "Epoch 00010: val_loss improved from 0.52520 to 0.51092, saving model to best_model.h5\n",
      "46/46 [==============================] - 134s 3s/step - loss: 0.5249 - accuracy: 0.8893 - val_loss: 0.5109 - val_accuracy: 0.9187\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5073 - accuracy: 0.8962\n",
      "Epoch 00011: val_loss improved from 0.51092 to 0.50117, saving model to best_model.h5\n",
      "46/46 [==============================] - 135s 3s/step - loss: 0.5073 - accuracy: 0.8962 - val_loss: 0.5012 - val_accuracy: 0.9500\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4939 - accuracy: 0.9153\n",
      "Epoch 00012: val_loss improved from 0.50117 to 0.48778, saving model to best_model.h5\n",
      "46/46 [==============================] - 135s 3s/step - loss: 0.4939 - accuracy: 0.9153 - val_loss: 0.4878 - val_accuracy: 0.9250\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4856 - accuracy: 0.9208\n",
      "Epoch 00013: val_loss improved from 0.48778 to 0.48266, saving model to best_model.h5\n",
      "46/46 [==============================] - 134s 3s/step - loss: 0.4856 - accuracy: 0.9208 - val_loss: 0.4827 - val_accuracy: 0.8938\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4791 - accuracy: 0.9085\n",
      "Epoch 00014: val_loss improved from 0.48266 to 0.47914, saving model to best_model.h5\n",
      "46/46 [==============================] - 132s 3s/step - loss: 0.4791 - accuracy: 0.9085 - val_loss: 0.4791 - val_accuracy: 0.8375\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4696 - accuracy: 0.9098\n",
      "Epoch 00015: val_loss improved from 0.47914 to 0.45005, saving model to best_model.h5\n",
      "46/46 [==============================] - 137s 3s/step - loss: 0.4696 - accuracy: 0.9098 - val_loss: 0.4501 - val_accuracy: 0.9312\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4551 - accuracy: 0.9153\n",
      "Epoch 00016: val_loss improved from 0.45005 to 0.43288, saving model to best_model.h5\n",
      "46/46 [==============================] - 138s 3s/step - loss: 0.4551 - accuracy: 0.9153 - val_loss: 0.4329 - val_accuracy: 0.9875\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.9344\n",
      "Epoch 00017: val_loss improved from 0.43288 to 0.42392, saving model to best_model.h5\n",
      "46/46 [==============================] - 133s 3s/step - loss: 0.4526 - accuracy: 0.9344 - val_loss: 0.4239 - val_accuracy: 0.9812\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4423 - accuracy: 0.9331\n",
      "Epoch 00018: val_loss improved from 0.42392 to 0.41907, saving model to best_model.h5\n",
      "46/46 [==============================] - 137s 3s/step - loss: 0.4423 - accuracy: 0.9331 - val_loss: 0.4191 - val_accuracy: 0.9812\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4346 - accuracy: 0.9481\n",
      "Epoch 00019: val_loss did not improve from 0.41907\n",
      "46/46 [==============================] - 134s 3s/step - loss: 0.4346 - accuracy: 0.9481 - val_loss: 0.4221 - val_accuracy: 0.9500\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4313 - accuracy: 0.9385\n",
      "Epoch 00020: val_loss improved from 0.41907 to 0.40186, saving model to best_model.h5\n",
      "46/46 [==============================] - 135s 3s/step - loss: 0.4313 - accuracy: 0.9385 - val_loss: 0.4019 - val_accuracy: 0.9750\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4110 - accuracy: 0.9467\n",
      "Epoch 00021: val_loss improved from 0.40186 to 0.38723, saving model to best_model.h5\n",
      "46/46 [==============================] - 136s 3s/step - loss: 0.4110 - accuracy: 0.9467 - val_loss: 0.3872 - val_accuracy: 0.9812\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4061 - accuracy: 0.9522\n",
      "Epoch 00022: val_loss did not improve from 0.38723\n",
      "46/46 [==============================] - 134s 3s/step - loss: 0.4061 - accuracy: 0.9522 - val_loss: 0.3881 - val_accuracy: 0.9812\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4043 - accuracy: 0.9481\n",
      "Epoch 00023: val_loss improved from 0.38723 to 0.37848, saving model to best_model.h5\n",
      "46/46 [==============================] - 134s 3s/step - loss: 0.4043 - accuracy: 0.9481 - val_loss: 0.3785 - val_accuracy: 0.9812\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.9508\n",
      "Epoch 00024: val_loss did not improve from 0.37848\n",
      "46/46 [==============================] - 135s 3s/step - loss: 0.4053 - accuracy: 0.9508 - val_loss: 0.3935 - val_accuracy: 0.9500\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3961 - accuracy: 0.9536\n",
      "Epoch 00025: val_loss improved from 0.37848 to 0.36774, saving model to best_model.h5\n",
      "46/46 [==============================] - 137s 3s/step - loss: 0.3961 - accuracy: 0.9536 - val_loss: 0.3677 - val_accuracy: 0.9812\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3790 - accuracy: 0.9590\n",
      "Epoch 00026: val_loss did not improve from 0.36774\n",
      "46/46 [==============================] - 135s 3s/step - loss: 0.3790 - accuracy: 0.9590 - val_loss: 0.3679 - val_accuracy: 0.9750\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.9658\n",
      "Epoch 00027: val_loss improved from 0.36774 to 0.35801, saving model to best_model.h5\n",
      "46/46 [==============================] - 138s 3s/step - loss: 0.3792 - accuracy: 0.9658 - val_loss: 0.3580 - val_accuracy: 0.9812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3735 - accuracy: 0.9590\n",
      "Epoch 00028: val_loss improved from 0.35801 to 0.34955, saving model to best_model.h5\n",
      "46/46 [==============================] - 136s 3s/step - loss: 0.3735 - accuracy: 0.9590 - val_loss: 0.3495 - val_accuracy: 0.9875\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.9604\n",
      "Epoch 00029: val_loss did not improve from 0.34955\n",
      "46/46 [==============================] - 133s 3s/step - loss: 0.3631 - accuracy: 0.9604 - val_loss: 0.3502 - val_accuracy: 0.9812\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3587 - accuracy: 0.9536\n",
      "Epoch 00030: val_loss improved from 0.34955 to 0.33224, saving model to best_model.h5\n",
      "46/46 [==============================] - 133s 3s/step - loss: 0.3587 - accuracy: 0.9536 - val_loss: 0.3322 - val_accuracy: 0.9937\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3520 - accuracy: 0.9617\n",
      "Epoch 00031: val_loss improved from 0.33224 to 0.32085, saving model to best_model.h5\n",
      "46/46 [==============================] - 132s 3s/step - loss: 0.3520 - accuracy: 0.9617 - val_loss: 0.3209 - val_accuracy: 0.9937\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3430 - accuracy: 0.9672\n",
      "Epoch 00032: val_loss did not improve from 0.32085\n",
      "46/46 [==============================] - 139s 3s/step - loss: 0.3430 - accuracy: 0.9672 - val_loss: 0.3211 - val_accuracy: 0.9875\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3395 - accuracy: 0.9740\n",
      "Epoch 00033: val_loss did not improve from 0.32085\n",
      "46/46 [==============================] - 136s 3s/step - loss: 0.3395 - accuracy: 0.9740 - val_loss: 0.3359 - val_accuracy: 0.9750\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3448 - accuracy: 0.9467\n",
      "Epoch 00034: val_loss did not improve from 0.32085\n",
      "46/46 [==============================] - 134s 3s/step - loss: 0.3448 - accuracy: 0.9467 - val_loss: 0.3392 - val_accuracy: 0.9750\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3405 - accuracy: 0.9658\n",
      "Epoch 00035: val_loss did not improve from 0.32085\n",
      "46/46 [==============================] - 134s 3s/step - loss: 0.3405 - accuracy: 0.9658 - val_loss: 0.3261 - val_accuracy: 0.9812\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3284 - accuracy: 0.9727\n",
      "Epoch 00036: val_loss did not improve from 0.32085\n",
      "46/46 [==============================] - 134s 3s/step - loss: 0.3284 - accuracy: 0.9727 - val_loss: 0.3277 - val_accuracy: 0.9812\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3359 - accuracy: 0.9686\n",
      "Epoch 00037: val_loss did not improve from 0.32085\n",
      "46/46 [==============================] - 138s 3s/step - loss: 0.3359 - accuracy: 0.9686 - val_loss: 0.3334 - val_accuracy: 0.9812\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3423 - accuracy: 0.9549\n",
      "Epoch 00038: val_loss improved from 0.32085 to 0.32004, saving model to best_model.h5\n",
      "46/46 [==============================] - 138s 3s/step - loss: 0.3423 - accuracy: 0.9549 - val_loss: 0.3200 - val_accuracy: 0.9875\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3264 - accuracy: 0.9754\n",
      "Epoch 00039: val_loss did not improve from 0.32004\n",
      "46/46 [==============================] - 133s 3s/step - loss: 0.3264 - accuracy: 0.9754 - val_loss: 0.3287 - val_accuracy: 0.9812\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3377 - accuracy: 0.9699\n",
      "Epoch 00040: val_loss did not improve from 0.32004\n",
      "46/46 [==============================] - 137s 3s/step - loss: 0.3377 - accuracy: 0.9699 - val_loss: 0.3265 - val_accuracy: 0.9812\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3384 - accuracy: 0.9577\n",
      "Epoch 00041: val_loss did not improve from 0.32004\n",
      "46/46 [==============================] - 138s 3s/step - loss: 0.3384 - accuracy: 0.9577 - val_loss: 0.3246 - val_accuracy: 0.9812\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3367 - accuracy: 0.9727\n",
      "Epoch 00042: val_loss did not improve from 0.32004\n",
      "46/46 [==============================] - 132s 3s/step - loss: 0.3367 - accuracy: 0.9727 - val_loss: 0.3264 - val_accuracy: 0.9812\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3324 - accuracy: 0.9604\n",
      "Epoch 00043: val_loss did not improve from 0.32004\n",
      "46/46 [==============================] - 135s 3s/step - loss: 0.3324 - accuracy: 0.9604 - val_loss: 0.3274 - val_accuracy: 0.9812\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3281 - accuracy: 0.9699\n",
      "Epoch 00044: val_loss did not improve from 0.32004\n",
      "46/46 [==============================] - 145s 3s/step - loss: 0.3281 - accuracy: 0.9699 - val_loss: 0.3252 - val_accuracy: 0.9812\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.9577\n",
      "Epoch 00045: val_loss did not improve from 0.32004\n",
      "46/46 [==============================] - 136s 3s/step - loss: 0.3388 - accuracy: 0.9577 - val_loss: 0.3262 - val_accuracy: 0.9812\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.9631\n",
      "Epoch 00046: val_loss did not improve from 0.32004\n",
      "46/46 [==============================] - 132s 3s/step - loss: 0.3386 - accuracy: 0.9631 - val_loss: 0.3288 - val_accuracy: 0.9812\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3370 - accuracy: 0.9754\n",
      "Epoch 00047: val_loss did not improve from 0.32004\n",
      "46/46 [==============================] - 134s 3s/step - loss: 0.3370 - accuracy: 0.9754 - val_loss: 0.3273 - val_accuracy: 0.9812\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.9699\n",
      "Epoch 00048: val_loss did not improve from 0.32004\n",
      "Restoring model weights from the end of the best epoch.\n",
      "46/46 [==============================] - 140s 3s/step - loss: 0.3406 - accuracy: 0.9699 - val_loss: 0.3294 - val_accuracy: 0.9812\n",
      "Epoch 00048: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f77bbe99438>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''Training the model'''\n",
    "\n",
    "total_epochs=50\n",
    "train_steps = train_generator.n//train_generator.batch_size\n",
    "val_steps    = val_generator.n//val_generator.batch_size\n",
    "\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch = train_steps,\n",
    "                    epochs=total_epochs,\n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps=val_steps,\n",
    "                    callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`y` argument is not supported when using `keras.utils.Sequence` as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-d2a34b1a6873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/avocado/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/avocado/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/avocado/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/avocado/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m                **kwargs):\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_none_or_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m       raise ValueError(\"`y` argument is not supported when using \"\n\u001b[0m\u001b[1;32m    900\u001b[0m                        \"`keras.utils.Sequence` as input.\")\n\u001b[1;32m    901\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_none_or_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `y` argument is not supported when using `keras.utils.Sequence` as input."
     ]
    }
   ],
   "source": [
    "'''total_epochs=50\n",
    "model.fit(xtrain, \n",
    "          ytrain, \n",
    "          epochs=total_epochs,\n",
    "          validation_data = np.array(list(validation_data)),\n",
    "          callbacks=callbacks)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_path = ./Models/SavedModel/\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./Models/SavedModel/assets\n"
     ]
    }
   ],
   "source": [
    "export_path = \"./Models/SavedModel/\"\n",
    "print('export_path = {}\\n'.format(export_path))\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./Models/SavedModel/\"\n",
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do ripe prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ripe_prediction = []\n",
    "\n",
    "for root, subdirs, files in os.walk(ripe_test_path):\n",
    "    for elem in files:\n",
    "        img = tf.keras.preprocessing.image.load_img(ripe_test_path+elem, target_size=(224, 224))\n",
    "        new_img = np.array(img, dtype=np.float64)/255.0\n",
    "        image = np.expand_dims(new_img, axis=0) \n",
    "        ripe_prediction.append(0 if model.predict(image) <0.5 else 1)\n",
    "ripe_truth = [0 for i in range(0, len(ripe_prediction))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do unripe prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "unripe_prediction = []\n",
    "\n",
    "for root, subdirs, files in os.walk(unripe_test_path):\n",
    "    for elem in files:\n",
    "        img = tf.keras.preprocessing.image.load_img(unripe_test_path+elem, target_size=(224, 224))\n",
    "        new_img = np.array(img, dtype=np.float64)/255.0\n",
    "        image = np.expand_dims(new_img, axis=0) \n",
    "        unripe_prediction.append(0 if model.predict(image) <0.5 else 1)\n",
    "unripe_truth = [1 for i in range(0, len(unripe_prediction))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "labels=[\"ripe\",\"unripe\"]\n",
    "def drow_confusion_matrix(y,ypred, labels):\n",
    "    matrix=confusion_matrix(y,ypred)\n",
    "    plt.figure(figsize=(15,10))\n",
    "    colors=[\"indianred\",\"lightseagreen\"]\n",
    "    sns.heatmap(matrix,xticklabels=labels,yticklabels=labels,cmap=colors,annot=True,fmt=\"d\")\n",
    "    plt.title(\"confusion Matrix\")\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ripe test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score : 1.0\n",
      "accuracy_score : 1.0\n",
      "recall_score : 1.0\n",
      "True_positive : 0, False_positive : 0, True_negative : 166, False_negative : 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ytest = ripe_truth\n",
    "y_pred = ripe_prediction\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,classification_report\n",
    "print('precision_score : '+str(precision_score(ytest, y_pred, average='weighted')))\n",
    "print('accuracy_score : '+str(accuracy_score(ytest, y_pred)))\n",
    "print('recall_score : '+str(recall_score(ytest, y_pred, average='weighted')))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(ytest, y_pred, labels=[0,1]).ravel()\n",
    "print('True_positive : '+str(tp)+', False_positive : '+str(fp)+', True_negative : '+str(tn)+', False_negative : '+str(fn))\n",
    "drow_confusion_matrix(ytest,y_pred, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unripe test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score : 1.0\n",
      "accuracy_score : 0.993006993006993\n",
      "recall_score : 0.993006993006993\n",
      "True_positive : 142, False_positive : 0, True_negative : 0, False_negative : 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ytest = unripe_truth\n",
    "y_pred = unripe_prediction\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,classification_report\n",
    "print('precision_score : '+str(precision_score(ytest, y_pred, average='weighted')))\n",
    "print('accuracy_score : '+str(accuracy_score(ytest, y_pred)))\n",
    "print('recall_score : '+str(recall_score(ytest, y_pred, average='weighted')))\n",
    "tn, fp, fn, tp = confusion_matrix(ytest, y_pred).ravel()\n",
    "print('True_positive : '+str(tp)+', False_positive : '+str(fp)+', True_negative : '+str(tn)+', False_negative : '+str(fn))\n",
    "drow_confusion_matrix(ytest,y_pred, labels)                                                                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avocado",
   "language": "python",
   "name": "avocado"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
